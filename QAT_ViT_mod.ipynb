{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cf2b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "import torch.ao.quantization.quantize_fx as quantize_fx\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0377c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceMetrics:\n",
    "    \"\"\"Class to track and compare model performance metrics\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def add_model_metrics(self, model_name: str, accuracy: float, \n",
    "                         inference_time: float, model_size: float,\n",
    "                         memory_usage: float = None):\n",
    "        \"\"\"Add metrics for a specific model\"\"\"\n",
    "        self.metrics[model_name] = {\n",
    "            'accuracy': accuracy,\n",
    "            'inference_time': inference_time,\n",
    "            'model_size': model_size,\n",
    "            'memory_usage': memory_usage\n",
    "        }\n",
    "    \n",
    "    def compare_models(self):\n",
    "        \"\"\"Generate comparison report\"\"\"\n",
    "        if len(self.metrics) < 2:\n",
    "            print(\"Need at least 2 models for comparison\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Print tabular comparison\n",
    "        print(f\"{'Model':<15} {'Accuracy':<12} {'Inf. Time (ms)':<15} {'Size (MB)':<12} {'Memory (MB)':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        for name, metrics in self.metrics.items():\n",
    "            memory_str = f\"{metrics['memory_usage']:.2f}\" if metrics['memory_usage'] else \"N/A\"\n",
    "            print(f\"{name:<15} {metrics['accuracy']:.4f}       \"\n",
    "                  f\"{metrics['inference_time']*1000:.2f}           \"\n",
    "                  f\"{metrics['model_size']:.2f}        {memory_str}\")\n",
    "        \n",
    "        # Calculate improvements/degradations\n",
    "        if 'FP32' in self.metrics and 'QAT_INT8' in self.metrics:\n",
    "            fp32 = self.metrics['FP32']\n",
    "            qat = self.metrics['QAT_INT8']\n",
    "            \n",
    "            acc_change = ((qat['accuracy'] - fp32['accuracy']) / fp32['accuracy']) * 100\n",
    "            speed_improvement = ((fp32['inference_time'] - qat['inference_time']) / fp32['inference_time']) * 100\n",
    "            size_reduction = ((fp32['model_size'] - qat['model_size']) / fp32['model_size']) * 100\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"QAT vs FP32 IMPROVEMENTS:\")\n",
    "            print(\"=\"*50)\n",
    "            print(f\"Accuracy change: {acc_change:+.2f}%\")\n",
    "            print(f\"Speed improvement: {speed_improvement:+.2f}%\")\n",
    "            print(f\"Model size reduction: {size_reduction:+.2f}%\")\n",
    "            \n",
    "            if qat['memory_usage'] and fp32['memory_usage']:\n",
    "                mem_reduction = ((fp32['memory_usage'] - qat['memory_usage']) / fp32['memory_usage']) * 100\n",
    "                print(f\"Memory usage reduction: {mem_reduction:+.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ab9774",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_model_size(model):\n",
    "    \"\"\"Calculate model size in MB\"\"\"\n",
    "    param_size = 0\n",
    "    buffer_size = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    \n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    \n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_all_mb\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current GPU memory usage in MB\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated() / 1024**2\n",
    "    return None\n",
    "\n",
    "def evaluate_model(model, data_loader, device, num_classes=10):\n",
    "    \"\"\"Evaluate model and return accuracy and detailed metrics\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    inference_times = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Measure inference time\n",
    "            start_time = time.time()\n",
    "            outputs = model(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            inference_times.append(end_time - start_time)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    avg_inference_time = np.mean(inference_times)\n",
    "    \n",
    "    return accuracy, avg_inference_time, all_preds, all_targets\n",
    "\n",
    "def prepare_data(batch_size=64, num_workers=2):\n",
    "    \"\"\"Prepare CIFAR-100 dataset with appropriate transforms for ViT\"\"\"\n",
    "    \n",
    "    # Transforms for training and testing\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # ViT expects 224x224 images\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomGrayscale(p=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # ImageNet normalization\n",
    "    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    ])\n",
    "    \n",
    "    # Load CIFAR-100 dataset\n",
    "    train_dataset = torchvision.datasets.CIFAR100(\n",
    "        root='./data', train=True, download=True, transform=transform_train\n",
    "    )\n",
    "    \n",
    "    test_dataset = torchvision.datasets.CIFAR100(\n",
    "        root='./data', train=False, download=True, transform=transform_test\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "def create_vit_model(num_classes=100):\n",
    "    \"\"\"Create and modify ViT Large model for CIFAR-100\"\"\"\n",
    "    # Load pre-trained ViT Large model\n",
    "    model = timm.create_model('vit_large_patch16_224', pretrained=True)\n",
    "    \n",
    "    # Modify the classifier for CIFAR-100 (100 classes)\n",
    "    model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, device, num_epochs=3):\n",
    "    \"\"\"Training function\"\"\"\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    print(f\"\\nTraining on {device} for {num_epochs} epochs...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            if i % 100 == 99:  # Print every 100 batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], '\n",
    "                      f'Loss: {running_loss/100:.4f}, '\n",
    "                      f'Acc: {100*correct/total:.2f}%')\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] completed. Training Accuracy: {epoch_acc:.2f}%')\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef430b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting QAT ViT Large Training Pipeline on CIFAR-100...\n",
      "======================================================================\n",
      "Preparing CIFAR-100 dataset...\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:20<00:00, 8.11MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-100-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Using device: cuda\n",
      "ViT Model: Large (vit_large_patch16_224)\n",
      "Dataset: CIFAR-100 (100 classes)\n",
      "\n",
      "======================================================================\n",
      "PART 1: FP32 ViT LARGE MODEL TRAINING\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the complete QAT pipeline\"\"\"\n",
    "    \n",
    "    print(\"Starting QAT ViT Large Training Pipeline on CIFAR-100...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Configuration\n",
    "    batch_size = 16   # Smaller batch size due to ViT Large memory requirements\n",
    "    num_epochs = 2    # Reduced for demonstration\n",
    "    learning_rate = 5e-6  # Lower learning rate for large model\n",
    "    num_classes = 100\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"Preparing CIFAR-100 dataset...\")\n",
    "    train_loader, test_loader = prepare_data(batch_size=batch_size)\n",
    "    \n",
    "    # CIFAR-100 class names (100 fine-grained classes)\n",
    "    class_names = [\n",
    "        'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
    "        'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
    "        'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
    "        'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
    "        'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
    "        'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
    "        'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
    "        'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
    "        'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
    "        'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
    "        'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
    "        'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
    "        'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
    "        'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman',\n",
    "        'worm'\n",
    "    ]\n",
    "    \n",
    "    # Initialize metrics tracker\n",
    "    metrics_tracker = PerformanceMetrics()\n",
    "    \n",
    "    # Check device availability\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"ViT Model: Large (vit_large_patch16_224)\")\n",
    "    print(f\"Dataset: CIFAR-100 ({num_classes} classes)\")\n",
    "    \n",
    "    # ========================\n",
    "    # PART 1: FP32 Model Training and Evaluation\n",
    "    # ========================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PART 1: FP32 ViT LARGE MODEL TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create FP32 model\n",
    "    model_fp32 = create_vit_model(num_classes)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model_fp32.parameters())/1e6:.1f}M\")\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_fp32 = optim.AdamW(model_fp32.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "    \n",
    "    # Train FP32 model\n",
    "    train_model(model_fp32, train_loader, criterion, optimizer_fp32, device, num_epochs)\n",
    "    \n",
    "    # Evaluate FP32 model\n",
    "    print(\"\\nEvaluating FP32 model...\")\n",
    "    model_fp32.eval()\n",
    "    fp32_accuracy, fp32_inf_time, fp32_preds, fp32_targets = evaluate_model(\n",
    "        model_fp32, test_loader, device, num_classes\n",
    "    )\n",
    "    \n",
    "    # Get FP32 model metrics\n",
    "    fp32_size = get_model_size(model_fp32)\n",
    "    fp32_memory = get_memory_usage()\n",
    "    \n",
    "    metrics_tracker.add_model_metrics(\n",
    "        'FP32', fp32_accuracy, fp32_inf_time, fp32_size, fp32_memory\n",
    "    )\n",
    "    \n",
    "    print(f\"FP32 ViT Large - Accuracy: {fp32_accuracy:.4f}, \"\n",
    "          f\"Avg Inference Time: {fp32_inf_time*1000:.2f}ms, \"\n",
    "          f\"Model Size: {fp32_size:.2f}MB\")\n",
    "    \n",
    "    # ========================\n",
    "    # PART 2: QAT Model Training\n",
    "    # ========================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PART 2: QAT ViT LARGE MODEL TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Move model to CPU for quantization preparation\n",
    "    model_fp32.to(\"cpu\")\n",
    "    \n",
    "    # Prepare example inputs for FX graph mode quantization\n",
    "    example_inputs = (torch.randn(1, 3, 224, 224),)\n",
    "    \n",
    "    # Get QAT configuration\n",
    "    qconfig_mapping = torch.ao.quantization.get_default_qat_qconfig_mapping(\"x86\")\n",
    "    \n",
    "    # Prepare model for QAT\n",
    "    print(\"Preparing ViT Large for QAT...\")\n",
    "    model_prepared = quantize_fx.prepare_qat_fx(model_fp32, qconfig_mapping, example_inputs)\n",
    "    \n",
    "    # Move back to training device\n",
    "    model_prepared.to(device)\n",
    "    \n",
    "    # Create new optimizer for QAT training (even lower learning rate)\n",
    "    optimizer_qat = optim.AdamW(model_prepared.parameters(), lr=learning_rate/10, weight_decay=0.01)\n",
    "    \n",
    "    # QAT Training (typically fewer epochs)\n",
    "    print(\"Starting QAT fine-tuning for ViT Large...\")\n",
    "    train_model(model_prepared, train_loader, criterion, optimizer_qat, device, num_epochs)\n",
    "    \n",
    "    # ========================\n",
    "    # PART 3: Convert to INT8 and Evaluate\n",
    "    # ========================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PART 3: INT8 CONVERSION AND EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Convert to INT8 (must be done on CPU)\n",
    "    model_prepared.to(\"cpu\")\n",
    "    model_prepared.eval()\n",
    "    \n",
    "    print(\"Converting ViT Large to INT8 model...\")\n",
    "    model_int8_qat = quantize_fx.convert_fx(model_prepared)\n",
    "    \n",
    "    # Evaluate INT8 model\n",
    "    print(\"Evaluating INT8 QAT ViT Large model...\")\n",
    "    qat_accuracy, qat_inf_time, qat_preds, qat_targets = evaluate_model(\n",
    "        model_int8_qat, test_loader, \"cpu\", num_classes\n",
    "    )\n",
    "    \n",
    "    # Get QAT model metrics\n",
    "    qat_size = get_model_size(model_int8_qat)\n",
    "    qat_memory = get_memory_usage()\n",
    "    \n",
    "    metrics_tracker.add_model_metrics(\n",
    "        'QAT_INT8', qat_accuracy, qat_inf_time, qat_size, qat_memory\n",
    "    )\n",
    "    \n",
    "    print(f\"QAT INT8 ViT Large - Accuracy: {qat_accuracy:.4f}, \"\n",
    "          f\"Avg Inference Time: {qat_inf_time*1000:.2f}ms, \"\n",
    "          f\"Model Size: {qat_size:.2f}MB\")\n",
    "    \n",
    "    # ========================\n",
    "    # PART 4: Performance Comparison and Analysis\n",
    "    # ========================\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PART 4: PERFORMANCE ANALYSIS - ViT LARGE on CIFAR-100\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Display comprehensive comparison\n",
    "    metrics_tracker.compare_models()\n",
    "    \n",
    "    # Generate top-5 accuracy for CIFAR-100\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TOP-5 ACCURACY ANALYSIS:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    def calculate_top5_accuracy(model, data_loader, device):\n",
    "        model.eval()\n",
    "        correct_top5 = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in data_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                outputs = model(data)\n",
    "                _, pred = outputs.topk(5, 1, True, True)\n",
    "                pred = pred.t()\n",
    "                correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "                correct_top5 += correct[:5].reshape(-1).float().sum(0, keepdim=True).item()\n",
    "                total += target.size(0)\n",
    "        \n",
    "        return correct_top5 / total\n",
    "    \n",
    "    # Calculate top-5 accuracy for both models\n",
    "    model_fp32.to(device)\n",
    "    fp32_top5 = calculate_top5_accuracy(model_fp32, test_loader, device)\n",
    "    qat_top5 = calculate_top5_accuracy(model_int8_qat, test_loader, \"cpu\")\n",
    "    \n",
    "    print(f\"FP32 ViT Large Top-5 Accuracy: {fp32_top5:.4f}\")\n",
    "    print(f\"QAT INT8 ViT Large Top-5 Accuracy: {qat_top5:.4f}\")\n",
    "    print(f\"Top-5 Accuracy Retention: {(qat_top5/fp32_top5)*100:.2f}%\")\n",
    "    \n",
    "    # Generate classification reports (showing top 10 classes for brevity)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SAMPLE CLASSIFICATION METRICS (First 10 classes):\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    sample_classes = class_names[:10]\n",
    "    \n",
    "    # Filter predictions and targets for first 10 classes only\n",
    "    fp32_sample_mask = [i for i, target in enumerate(fp32_targets) if target < 10]\n",
    "    qat_sample_mask = [i for i, target in enumerate(qat_targets) if target < 10]\n",
    "    \n",
    "    if fp32_sample_mask and qat_sample_mask:\n",
    "        fp32_sample_preds = [fp32_preds[i] for i in fp32_sample_mask]\n",
    "        fp32_sample_targets = [fp32_targets[i] for i in fp32_sample_mask]\n",
    "        qat_sample_preds = [qat_preds[i] for i in qat_sample_mask]\n",
    "        qat_sample_targets = [qat_targets[i] for i in qat_sample_mask]\n",
    "        \n",
    "        print(\"\\nFP32 ViT Large (Sample Classes):\")\n",
    "        print(classification_report(fp32_sample_targets, fp32_sample_preds, \n",
    "                                  target_names=sample_classes, labels=list(range(10))))\n",
    "        \n",
    "        print(\"\\nQAT INT8 ViT Large (Sample Classes):\")\n",
    "        print(classification_report(qat_sample_targets, qat_sample_preds, \n",
    "                                  target_names=sample_classes, labels=list(range(10))))\n",
    "    \n",
    "    # Save models\n",
    "    print(\"\\nSaving models...\")\n",
    "    torch.save(model_fp32.state_dict(), 'vit_large_fp32_cifar100.pth')\n",
    "    torch.save(model_int8_qat.state_dict(), 'vit_large_qat_int8_cifar100.pth')\n",
    "    \n",
    "    print(\"\\nQAT ViT Large Training Pipeline on CIFAR-100 Completed!\")\n",
    "    print(\"Models saved successfully.\")\n",
    "    print(f\"Final Model Size Reduction: {((fp32_size - qat_size) / fp32_size) * 100:.1f}%\")\n",
    "    \n",
    "    return model_fp32, model_int8_qat, metrics_tracker\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete pipeline\n",
    "    fp32_model, qat_model, metrics = main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
